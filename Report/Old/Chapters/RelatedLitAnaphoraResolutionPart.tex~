\section{Anaphora Resolution Overview}

\textit{Anaphora Resolution} is arguably one of the most challenging problems in Natural Language Processing and has seen many approaches being followed for tackling the same \cite{mitkov}. \begin{comment} presents probably the most comprehensive survey of such approaches. \end{comment}
In this section we provide an overview of some of the anaphora resolution literature as relevant to our work.

\subsection{Terminology}
The roots of the word \textit{anaphora} can be traced to Ancient Greece and literally means "the act of carrying back upstream".(\cite{mitkov}). In other words, anaphora is a (concise) alias pointing back to some previous item, in a text. The (concise) alias is termed as an \textit{anaphor} and item it points to \textit{antecedent}, and the process of resolving an anaphor to its correct antecedent is called \textit{anaphora resolution}.

Example : Nehru and his colleagues had been released as the British Cabinet Mission arrived to propose plans for transfer of power.

In the above sentence the pronoun 'his' is an anaphor referring to the antecedent 'Nehru'.

\subsection{Pronominal Anaphora}
Amongst the most widespread anaphora are pronominal anaphora, an example of which we saw just above.
The example was an instance of an \textit{intra-sentential anaphor}, likewise, we could also have \textit{inter-sentential anaphors}, where the anaphor and antecedent occur in different sentences. Needless to say, the intersentential anaphora are more challenging to resolve.

The most common occurrences of pronominal anaphora include third person pronouns ('he','she', 'they' etc).
Some of the pronoun instances could be non-anaphoric as well. For e.g in "It is said that ...", the pronoun 'it' does not refer to any antecedent.

\textit{Relative pronouns} (like 'who','which') form a relatively less studied form of pronominal anaphora.

Example : Bhabha was the nephew of Meherbai Hormusji, who was married to Dorab Tata.

In the above sentence, 'who' refers to 'Meherbai Hormusji'.
\subsection{Key Pronominal Anaphora Resolution Approaches}
Typically the anaphora resolution problem reduces to selecting an antecedent from a list of candidates. The latest trend in anaphora resolution is to avoid using any domain knowledge of the corpus in choosing from the candidates.
We briefly describe some of the key knowledge-poor approaches here:
\subsubsection{Lappin and Leass' RAP algorithm}
The Resolution of Anaphora Procedure (RAP) by Lappin and Leass was one of the first knowledge poor anaphora resolution algorithms with a high rate of correct analyses. The algorithm computes salience scores for each of the candidate antecedents  using in-depth full grammatical parsing of the text.

The candidate antecedents are noun phrases identified using the parsing of the text. Some of the key parameters(or salience weights) used by the RAP algorithm for computing those salience scores are:
\begin{itemize}
 \item[]{\textit{Grammatical Role} : whereby higher salience weights are assigned to (i) subject over non-subject candidate noun phrases (ii) direct objects over other complements (iii)arguments of a verb over its adjuncts (iv) head nouns over complements of the head nouns}
\item[]{\textit{Proximity} : number of terms separating the pronominal anaphor from the candidate noun phrase}
\item[]{\textit{Sentence Recency} : number of sentences between the anaphor and the candidate noun phrase.}
\item[]{\textit{Morphological Agreement} : whereby unsuitable candidate noun phrases are filtered out based on gender,number and person agreement between the anaphor and the candidate noun phrase.}
\end{itemize}
The candidate having the maximum salience score is chosen as the antecedent referred to by the pronoun occurrence.
The details can be found in \cite{lappin}. The authors tested the algorithm on a computer manual text containing 360 pronoun occurrences which the authors claim  to successfully resolved to their correct antecedents in 86\% of the cases. 
\subsubsection{Kennedy and Boguraev's approach without a Parser}
This algorithm is largely based on the RAP algorithm just discussed above except that it requires the output of a Part-of-Speech Tagger instead of using a Parser.

In the absence of syntactic configurational information, the salience weights are then computed using only the grammatical function annotations from the part of speech tagger. The salience weights are computed using candidate noun phrase proximity. As in the case of RAP, unsuitable candidates are filtered out based on gender, number, person non-agreement. 

The details can be found in \cite{KennedyB96}. The authors claim 75\% accuracy on a diverse set of documents.

\subsubsection{Mitkov's Robust Knowledge Poor Approach}
This is yet another salience based approach which requires the output of a part of speech tagger, and employs antecedent indicators similar to the salience weights discussed in the above two approaches. However the approach is far more exhaustive having identified several antecedent indicators on the basis of empirical studies. Each of those indicators is assigned a score (-1,0,1,2) and the candidate with  the maximum aggregate score is identified as the antecedent for the anaphor.\begin{comment}Moreover it also takes into account the typical behaviour of common verbs thereby penalizing or boosting the salience of its preceeding/following noun phrases. For e.g  'discuss', 'illustrate', 'present' whereby \end{comment}

Evaluation reports an accuracy of 89.7\%, which is probably amongst the highest. The details can be obtained in \cite{Mitkov98}. MARS \footnote{\href{http://clg.wlv.ac.uk/demos/MARS/index.php}{http://clg.wlv.ac.uk/demos/MARS/index.php}} (Mitkov's Anaphora Resolution System) incorporates the schemes of the approach and is available for an online demo.

\subsubsection{Charniak and Elsner's Expectation Maximization Approach}
%This approach is one of the latest, followed in a digression from the salience based approaches discussed earlier. 
Unlike the salience based approaches discussed above, this approach uses the Expectation Maximization technique.
The authors claim results comparable to other openly available Anaphora Resolution Systems, reporting an accuracy of 68.6\% on the dataset annotated by Niyu Ge \cite{geCharniak}.

The algorithm relies on the output of a grammatical parser and chooses the antecedent based on a probabilistic model, the parameters of which are almost all learnt using Expectation Maximization. 

Some of the key parameters are:

\begin{itemize}
 \item[]\underline{p(antecedent$|$context)}: Probability of selecting a candidate antecedent given the syntactic context obtained from the parser annotations. The context information taken into account include position of the pronoun, position 
\item[]\underline{p(person$|$antecedent)}: Probability of predicting whether the to-be-resolved pronoun is first, second or third person given the antecedent, for a certain antecedent.
\item[]\underline{p(gender$|$antecedent)}: Probability that a given antecedent will generate a masculine or feminine pronoun.
\item[]\underline{p(number$|$antecedent)}: Probability that a given antecedent will generate a plural or singular pronoun.
\end{itemize}
%Since Expectation Maximization has not had success in most NLP tasks like Part-Of-Speech Tagging, Named Entity Recognition 
The details can be obtained in \cite{CharniakE09}. The details of Expectation Maximization can be found in \cite{Dempster77}.

\subsection{Openly Available Anaphora Resolution Systems}
There are only a handful of openly available Anaphora Resolution Systems. 

\textit{JavaRAP} \footnote{\href{http://aye.comp.nus.edu.sg/~qiu/NLPTools/JavaRAP.html}{http://aye.comp.nus.edu.sg/~qiu/NLPTools/JavaRAP.html}} is an implementation of the Lappin and Leass' RAP algorithm

\textit{GuiTAR} \footnote{\href{http://cswww.essex.ac.uk/Research/nle/GuiTAR/}{http://cswww.essex.ac.uk/Research/nle/GuiTAR/}} borrows heavily from Mitkov's Robust Knowledge Poor Approach. 

Charniak and Elsner have implemented their Expectation Maximization approach and made it available openly as \textit{emPronoun} \footnote{\href{http://bllip.cs.brown.edu/download/}{http://bllip.cs.brown.edu/download/}}.
which we chose \textit{emPronoun} as the Anaphora Resolution Component in our proposed system prototype which will discussed in Chapter \ref{propSys}.